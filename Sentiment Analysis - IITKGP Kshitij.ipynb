{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe9871a-4389-4f48-acc6-cc4f9036b75c",
   "metadata": {},
   "source": [
    "# Project Name: Sentiment Analysis of comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed67b33a-ef45-4790-87ee-af1905cd61f9",
   "metadata": {},
   "source": [
    "### Goal: To predict sentiment of comments using Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60722f96-8e6c-4b8d-990e-e0daf3ddf091",
   "metadata": {},
   "source": [
    "**Dataset**: IIT - KGP Kshitij AI Hackathon dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dfd44b-2d0b-4cae-8174-b17cb4ae1361",
   "metadata": {},
   "source": [
    "**About the Project**: With the increasing reliance on online platforms for reviews, feedback, and social media interactions, understanding customer sentiment has become a critical task for businesses across industries. Sentiment analysis allows companies to gain deeper insights into customer opinions, which can help improve products, services, and customer satisfaction. However, interpreting the true sentiment behind vast amounts of text data, such as reviews, comments, and social media posts, can be challenging due to the nuances of language, tone, and context.\n",
    "\n",
    "To address this, we are developing a Natural Language Processing (NLP) model that analyzes customer feedback and classifies the sentiment expressed in the text. By training the model on a variety of text data with labeled sentiments, it will be able to accurately predict whether a given review or comment is positive, negative, or neutral. This tool will help businesses quickly identify areas of concern and opportunities for improvement by analyzing large volumes of customer feedback. The ultimate goal is to provide actionable insights that can enhance decision-making, improve customer relationships, and drive business success."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5082ed5b-4d0a-46ab-ac7c-7768c255f15f",
   "metadata": {},
   "source": [
    "### Section 1: Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc007bd-e7be-40ed-8900-526320f9d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "947e3d99-7f87-4bf4-83fd-78af06a0d37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\"Comments,Sentiment\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"I love the new features in the update.,Positive\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Fast and efficient customer support.,Positive\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"The product quality is amazing!,Positive\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Fast and efficient customer support.,Positive\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"I am disappointed with the delivery.,Neutral\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>\"Fast and efficient customer support.,Positive\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>\"The room was clean but noisy.,Neutral\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>\"The product quality is amazing!,Positive\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>\"I am disappointed with the delivery.,Negative\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>\"The food was cold and tasteless.,Negative\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20003 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    \"Comments,Sentiment\"\n",
       "0      \"I love the new features in the update.,Positive\"\n",
       "1        \"Fast and efficient customer support.,Positive\"\n",
       "2             \"The product quality is amazing!,Positive\"\n",
       "3        \"Fast and efficient customer support.,Positive\"\n",
       "4         \"I am disappointed with the delivery.,Neutral\"\n",
       "...                                                  ...\n",
       "19998    \"Fast and efficient customer support.,Positive\"\n",
       "19999            \"The room was clean but noisy.,Neutral\"\n",
       "20000         \"The product quality is amazing!,Positive\"\n",
       "20001    \"I am disappointed with the delivery.,Negative\"\n",
       "20002        \"The food was cold and tasteless.,Negative\"\n",
       "\n",
       "[20003 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = r\"C:\\Users\\user\\Desktop\\Code Fragments\\Machine Learning\\Datasets\\AI-Hackathon-test-data-set.csv\"\n",
    "data = pd.read_csv(url)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d280659-6348-4479-96b8-0c556e7e2b42",
   "metadata": {},
   "source": [
    "We have ~ 20000 rows in our dataset, but the dataset hasn't be converted into our desired dataframe format.<br>\n",
    "We'll have to manipulate it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d79f887-bc23-43f3-9efc-a5613b0c671f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\"Comments,Sentiment\"</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"I love the new features in the update.,Positive\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I love the new features in the update.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Fast and efficient customer support.,Positive\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast and efficient customer support.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"The product quality is amazing!,Positive\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>The product quality is amazing!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Fast and efficient customer support.,Positive\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast and efficient customer support.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"I am disappointed with the delivery.,Neutral\"</td>\n",
       "      <td>,Neutral</td>\n",
       "      <td>I am disappointed with the delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>\"Fast and efficient customer support.,Positive\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast and efficient customer support.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>\"The room was clean but noisy.,Neutral\"</td>\n",
       "      <td>,Neutral</td>\n",
       "      <td>The room was clean but noisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>\"The product quality is amazing!,Positive\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>The product quality is amazing!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>\"I am disappointed with the delivery.,Negative\"</td>\n",
       "      <td>Negative</td>\n",
       "      <td>I am disappointed with the delivery.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>\"The food was cold and tasteless.,Negative\"</td>\n",
       "      <td>Negative</td>\n",
       "      <td>The food was cold and tasteless.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20003 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    \"Comments,Sentiment\" Sentiment  \\\n",
       "0      \"I love the new features in the update.,Positive\"  Positive   \n",
       "1        \"Fast and efficient customer support.,Positive\"  Positive   \n",
       "2             \"The product quality is amazing!,Positive\"  Positive   \n",
       "3        \"Fast and efficient customer support.,Positive\"  Positive   \n",
       "4         \"I am disappointed with the delivery.,Neutral\"  ,Neutral   \n",
       "...                                                  ...       ...   \n",
       "19998    \"Fast and efficient customer support.,Positive\"  Positive   \n",
       "19999            \"The room was clean but noisy.,Neutral\"  ,Neutral   \n",
       "20000         \"The product quality is amazing!,Positive\"  Positive   \n",
       "20001    \"I am disappointed with the delivery.,Negative\"  Negative   \n",
       "20002        \"The food was cold and tasteless.,Negative\"  Negative   \n",
       "\n",
       "                                     Comments  \n",
       "0      I love the new features in the update.  \n",
       "1        Fast and efficient customer support.  \n",
       "2             The product quality is amazing!  \n",
       "3        Fast and efficient customer support.  \n",
       "4         I am disappointed with the delivery  \n",
       "...                                       ...  \n",
       "19998    Fast and efficient customer support.  \n",
       "19999            The room was clean but noisy  \n",
       "20000         The product quality is amazing!  \n",
       "20001    I am disappointed with the delivery.  \n",
       "20002        The food was cold and tasteless.  \n",
       "\n",
       "[20003 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Sentiment\"] = data['\"Comments,Sentiment\"'].apply(lambda x: x[-9:-1])\n",
    "data[\"Comments\"] = data['\"Comments,Sentiment\"'].apply(lambda x: x[1:-10])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb60704b-ce6e-4127-b436-0997e8f9f2d1",
   "metadata": {},
   "source": [
    "Now that we have both the comments & sentiments separated, we can drop the attached column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01cb0c63-2dd5-4e20-9bca-08b217b189dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I love the new features in the update.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast and efficient customer support.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>The product quality is amazing!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast and efficient customer support.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,Neutral</td>\n",
       "      <td>I am disappointed with the delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Fast and efficient customer support.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>,Neutral</td>\n",
       "      <td>The room was clean but noisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>Positive</td>\n",
       "      <td>The product quality is amazing!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>Negative</td>\n",
       "      <td>I am disappointed with the delivery.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>Negative</td>\n",
       "      <td>The food was cold and tasteless.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20003 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentiment                                Comments\n",
       "0      Positive  I love the new features in the update.\n",
       "1      Positive    Fast and efficient customer support.\n",
       "2      Positive         The product quality is amazing!\n",
       "3      Positive    Fast and efficient customer support.\n",
       "4      ,Neutral     I am disappointed with the delivery\n",
       "...         ...                                     ...\n",
       "19998  Positive    Fast and efficient customer support.\n",
       "19999  ,Neutral            The room was clean but noisy\n",
       "20000  Positive         The product quality is amazing!\n",
       "20001  Negative    I am disappointed with the delivery.\n",
       "20002  Negative        The food was cold and tasteless.\n",
       "\n",
       "[20003 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns = ['\"Comments,Sentiment\"'], inplace = True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eddadf0-6a05-43f5-a096-451ff63e0247",
   "metadata": {},
   "source": [
    "Since our dataframe is ready, lets move on to our data manipulation phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972adc0f-7619-4dc4-8519-8fa90de97fd7",
   "metadata": {},
   "source": [
    "### Section 2: Data Cleaning / Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650d01f3-f3db-4a87-aadf-d2ee5e1c88f0",
   "metadata": {},
   "source": [
    "Initially, we can encode our sentiment values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "953c1aad-203c-4ec5-a134-8b1f0432e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"Positive\": 1,\n",
    "    \"Negative\": -1,\n",
    "    \",Neutral\": 0\n",
    "}\n",
    "data[\"Sentiment\"] = data[\"Sentiment\"].map(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67288f8-6124-49bd-8e5b-7802011583f7",
   "metadata": {},
   "source": [
    "Lets start with dealing with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e117243-93bd-4fad-8003-a3dfb43665d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Sentiment, Comments]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Sentiment, Comments]\n",
      "Index: []\n",
      "       Sentiment Comments\n",
      "86             0         \n",
      "153           -1         \n",
      "180            1         \n",
      "181           -1         \n",
      "202            1         \n",
      "...          ...      ...\n",
      "19854         -1         \n",
      "19903         -1         \n",
      "19941          1         \n",
      "19952         -1         \n",
      "19993          1         \n",
      "\n",
      "[1001 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data[data[\"Comments\"].isnull()])\n",
    "print(data[data[\"Sentiment\"].isnull()])\n",
    "print(data[data['Comments'] == ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a47e75e-6847-423b-9f32-936ad417ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"Comments\"]!='']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d685fe6f-8df0-48a0-8fa0-e338a504b2f3",
   "metadata": {},
   "source": [
    "As observed, our dataset has no null values.<br><br>\n",
    "One thing commonly observed in textual datasets is redundancy, lets deal with redundancy now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eb113fa-e677-4222-8f09-9b135bdf3a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       " 1    7461\n",
       "-1    7358\n",
       " 0    4183\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a921123-bfbb-446c-8417-0c8cf089d19d",
   "metadata": {},
   "source": [
    "As we can see, there is an deficit of neutral values. This may lead to underfitting / bias.<br>\n",
    "We have to deal with this inbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61d558ed-5e3b-4dab-8985-a62cb86803ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comments\n",
       "I love the new features in the update.    1827\n",
       "The product quality is amazing!           1811\n",
       "Fast and efficient customer support.      1805\n",
       "The app interface is confusing.           1801\n",
       "I am disappointed with the delivery.      1799\n",
       "Excellent ambiance and friendly staff.    1796\n",
       "The food was cold and tasteless.          1793\n",
       "Very poor customer service experience.    1793\n",
       "The service was okay, not great           1712\n",
       "The room was clean but noisy              1711\n",
       "The room was clean but noisy.              200\n",
       "The service was okay, not great.           193\n",
       "I am disappointed with the delivery        106\n",
       "Excellent ambiance and friendly staff      104\n",
       "Very poor customer service experience      100\n",
       "The food was cold and tasteless             95\n",
       "I love the new features in the update       91\n",
       "Fast and efficient customer support         90\n",
       "The app interface is confusing              87\n",
       "The product quality is amazing              86\n",
       "Blah blah blah                               1\n",
       "###random-text-12                            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Comments\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4cc879-fc2c-44a4-bf99-c08897e1e742",
   "metadata": {},
   "source": [
    "As we can see, our dataset is extremely poor in terms of redundancy & annotations.<br>\n",
    "With the occurence frequency in mind, the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a364d5-b4e6-4696-a98e-de263cf6566f",
   "metadata": {},
   "source": [
    "Countering the problems -\n",
    "\n",
    "- redundancy : we do not try to solve the redundancy since dropping duplicates greatly reduces data size\n",
    "- annotatons : for same data being annotated differently, we can adpot the annotation assigned to majority of the sub-data.\n",
    "- imbalance : we train using 4k values each, and then fine tune while adding left over data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fbcfc7-8c52-43c0-b438-96709b6047d2",
   "metadata": {},
   "source": [
    "#### Section 2.1 : Addressing Annotation Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "547f4434-e875-4bf9-9a40-622388928256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I love the new features in the update.',\n",
       "       'Fast and efficient customer support.',\n",
       "       'The product quality is amazing!',\n",
       "       'I am disappointed with the delivery',\n",
       "       'The service was okay, not great',\n",
       "       'The food was cold and tasteless.',\n",
       "       'I am disappointed with the delivery.',\n",
       "       'Excellent ambiance and friendly staff.',\n",
       "       'Very poor customer service experience.',\n",
       "       'The room was clean but noisy.', 'The app interface is confusing.',\n",
       "       'The room was clean but noisy',\n",
       "       'Excellent ambiance and friendly staff',\n",
       "       'Very poor customer service experience',\n",
       "       'The product quality is amazing',\n",
       "       'The food was cold and tasteless',\n",
       "       'The service was okay, not great.',\n",
       "       'Fast and efficient customer support',\n",
       "       'The app interface is confusing',\n",
       "       'I love the new features in the update', 'Blah blah blah',\n",
       "       '###random-text-12'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_coms = data['Comments'].unique()\n",
    "unique_coms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5701642-bc18-45aa-b63d-fa6378ff3cc2",
   "metadata": {},
   "source": [
    "We will proceed with removing the annotation inconsistency, by selecting the one with higher frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "369b4e7c-1ea4-4785-adac-e3266bd26f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unique_coms:\n",
    "    f1 = len(data[data[\"Comments\"] == i])\n",
    "    f2 = len(data[data[\"Comments\"] == i+\".\"])\n",
    "    if f1>f2:\n",
    "        data.drop(data[data['Comments'] == i+\".\"].index, inplace=True)\n",
    "    else:\n",
    "        data.drop(data[data['Comments'] == i].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15e7e8c2-5157-4fe4-9244-df1b39083260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I love the new features in the update.',\n",
       "       'Fast and efficient customer support.',\n",
       "       'The product quality is amazing!',\n",
       "       'The service was okay, not great',\n",
       "       'The food was cold and tasteless.',\n",
       "       'I am disappointed with the delivery.',\n",
       "       'Excellent ambiance and friendly staff.',\n",
       "       'Very poor customer service experience.',\n",
       "       'The app interface is confusing.', 'The room was clean but noisy',\n",
       "       'The product quality is amazing', 'Blah blah blah',\n",
       "       '###random-text-12'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Comments'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318c939-e4bf-409b-a018-bea66bd58fce",
   "metadata": {},
   "source": [
    "Now that our annotation issues are clear, we can move on data manipulation techniques for textual data.<br>\n",
    "We do the following:\n",
    "- remove stop words\n",
    "- lemmatize\n",
    "- basic formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fca50a2b-a218-47fc-88c6-84d0b576ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def process(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "data[\"Comments\"] = data[\"Comments\"].apply(lambda x: process(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9d1783-0bde-4924-b1de-8703ca9e30de",
   "metadata": {},
   "source": [
    "we create three parts of the dataset with different sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91e8f04b-6fbe-44e8-997f-b4def0af74d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_data = data[data[\"Sentiment\"] == 1]\n",
    "neg_data = data[data[\"Sentiment\"] == -1]\n",
    "net_data = data[data[\"Sentiment\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a4255e-4ec1-4189-b46f-3fcc0ed1981d",
   "metadata": {},
   "source": [
    "We merge the three data parts into one, while leaving out parts of positive & negative data to ensure equal representation to neutral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5ebd475-eb6b-4133-9242-3d224fc6867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pos = pos_data[:4000]\n",
    "use_neg = neg_data[:4000]\n",
    "data1 = pd.concat([use_pos, use_neg, net_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242b257d-6ff0-4680-8e66-ef71614b0e4c",
   "metadata": {},
   "source": [
    "We shuffle the data to maintain equal representation of data in all parts<br>\n",
    "[ Concept of Stratified Shuffle Split ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "203c9b23-11bb-4e28-98bb-54a82ab8e03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>-1</td>\n",
       "      <td>app interface confusing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>1</td>\n",
       "      <td>fast efficient customer support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9761</th>\n",
       "      <td>-1</td>\n",
       "      <td>disappointed delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9807</th>\n",
       "      <td>0</td>\n",
       "      <td>product quality amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11814</th>\n",
       "      <td>0</td>\n",
       "      <td>room clean noisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18833</th>\n",
       "      <td>0</td>\n",
       "      <td>room clean noisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3345</th>\n",
       "      <td>-1</td>\n",
       "      <td>app interface confusing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>-1</td>\n",
       "      <td>food cold tasteless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>1</td>\n",
       "      <td>app interface confusing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9132</th>\n",
       "      <td>-1</td>\n",
       "      <td>food cold tasteless</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11510 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentiment                         Comments\n",
       "1785          -1          app interface confusing\n",
       "7532           1  fast efficient customer support\n",
       "9761          -1            disappointed delivery\n",
       "9807           0          product quality amazing\n",
       "11814          0                 room clean noisy\n",
       "...          ...                              ...\n",
       "18833          0                 room clean noisy\n",
       "3345          -1          app interface confusing\n",
       "3865          -1              food cold tasteless\n",
       "2255           1          app interface confusing\n",
       "9132          -1              food cold tasteless\n",
       "\n",
       "[11510 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data1 = shuffle(data1, random_state = 42)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60fe013a-f1c8-4f7e-908e-da9a4cab237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data1[\"Comments\"]\n",
    "y = data1[\"Sentiment\"]\n",
    "\n",
    "x_train = x[:int(len(x)*0.75)]\n",
    "y_train = y[:int(len(y)*0.75)]\n",
    "x_test = x[int(len(x)*0.75):]\n",
    "y_test = y[int(len(y)*0.75):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d0e4749-60f2-4bdf-a648-b4f8f38c1b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fast efficient customer support'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3ca4e-e308-4fc9-a34f-9d6ac70be954",
   "metadata": {},
   "source": [
    "Our dataset is now ready for training phase 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f740f6f-125b-490f-82e0-847d7472aa9f",
   "metadata": {},
   "source": [
    "### Section 3: Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580f0ef8-3dca-45cb-a0e2-0a043aff6fd9",
   "metadata": {},
   "source": [
    "Google's bert is a very popular & relaible model.<br>\n",
    "We will procees with it's use for our goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9896373e-4cb7-4ebd-9a75-3b6bf452e303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer as BT, TFBertForSequenceClassification as tbsc\n",
    "from sklearn.metrics import classification_report as cr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9c9a04-2ee0-4be6-8922-7d5e7477b0a1",
   "metadata": {},
   "source": [
    "We use TFBertSC for our classification task and BertTokenizer of tokenizatiion of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5610809a-7244-49af-8e82-bddb143b6996",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BT.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "x_train_en = tokenizer.batch_encode_plus(x_train.astype(str).tolist(),\n",
    "                                              padding=True, \n",
    "                                              truncation=True,\n",
    "                                              max_length = 128,\n",
    "                                              return_tensors='tf')\n",
    " \n",
    "x_test_en= tokenizer.batch_encode_plus(x_test.astype(str).tolist(),\n",
    "                                              padding=True, \n",
    "                                              truncation=True,\n",
    "                                              max_length = 128,\n",
    "                                              return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "368378f1-f69a-4a10-80af-2e5c1291d52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = tbsc.from_pretrained('bert-base-uncased', num_labels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72dce09-79e5-41a1-b098-40f6e52ccd25",
   "metadata": {},
   "source": [
    "As we have three classifications, we set num_labels to 3.<br>\n",
    "This allows the model to predict values between [0-3)<br>\n",
    "To avoid errors, we add 1 to all values of y_train & y_test (since minimum value is -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65b93abe-9cee-4925-8821-bff5741f6b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train + 1\n",
    "y_test = y_test + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2832307-ef63-4bed-90ec-481984463d3b",
   "metadata": {},
   "source": [
    "Now, we compile our model using an optimizer, specifying criteria of loss & accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "836c10aa-0bed-4819-bac8-a19001fcf226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d46835-744a-46ea-8e5d-3a1975f01654",
   "metadata": {},
   "source": [
    "We finally fit our data into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01b120ec-b439-4f7c-a568-e803894621e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel.fit(\\n    [x_train_en['input_ids'], x_train_en['token_type_ids'], x_train_en['attention_mask']],\\n    y_train,\\n    validation_data=(\\n      [x_test_en['input_ids'], x_test_en['token_type_ids'], x_test_en['attention_mask']],y_test),\\n    batch_size=32,\\n    epochs=3\\n)\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model.fit(\n",
    "    [x_train_en['input_ids'], x_train_en['token_type_ids'], x_train_en['attention_mask']],\n",
    "    y_train,\n",
    "    validation_data=(\n",
    "      [x_test_en['input_ids'], x_test_en['token_type_ids'], x_test_en['attention_mask']],y_test),\n",
    "    batch_size=32,\n",
    "    epochs=3\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8138cd-5bc0-4315-ab57-dd41a41d2b9c",
   "metadata": {},
   "source": [
    "Since the training time is large, and no availability of an accelerator in this environment,<br>\n",
    "the model has been trained using a GPU in a kaggle notebook<br>\n",
    "( https://www.kaggle.com/code/gouravjana/notebookd86c597d7a/notebook?scriptVersionId=218325013 )<br>as an continuation to this project.<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
